<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Asako Mikami</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Asako Mikami</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CarlyWill Sloan, &#34;Racial Bias by Prosecutors: Evidence from Random Assignment&#34;</title>
      <link>/posts/jmp-review-carlywill-sloan/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/jmp-review-carlywill-sloan/</guid>
      <description>This blog post is coming up during a wave of Black Lives Matter protests in the United States and around the world. Black lives matter. This research paper by CarlyWill Sloan provides evidence on the racism of prosecutors that perpetuates the mass incarceration of Black men.1 Here is an excerpt from the abstract:
 Racial disparities in criminal justice outcomes are well-documented. However, there is little evidence on the extent to which racial bias exhibited by prosecutors is responsible for these disparities.</description>
    </item>
    
    <item>
      <title>Caroline Fry, &#34;Building Bridges: The impact of return migration by African scientists&#34;</title>
      <link>/posts/jmp-review-caroline-fry/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/jmp-review-caroline-fry/</guid>
      <description>The third installment in this series is Caroline Fry’s paper, “Building Bridges: The impact of migration by African scientists.” Here’s an excerpt from the abstract:
 Despite significant interest in the potential for ‘returnee’ scientists moving back to developing countries to connect developed and developing countries, prior work has found limited evidence of success. I shift the focus to the broader network of the returnee, and study the extent to which the return home of American-trained HIV researchers to African institutions impacts publication outcomes of non-migrant scientists in Africa.</description>
    </item>
    
    <item>
      <title>Chelsea E. Carter, &#34;Forts and Frontier: The U.S. Army and the Spatial Distribution of Population&#34;</title>
      <link>/posts/jmp-review-chelsea-carter/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/jmp-review-chelsea-carter/</guid>
      <description>The article I’m reviewing in this blog post is by Chelsea E. Carter, “Forts and Frontier: The U.S. Army and the Spatial Distribution of Population.” The topic is interesting and one I’ve never read about. Moreover, there’s a lot of methodological and computational tools used in this paper, and I was left with a lot of new readings to catch up on.
Me flipping to the reference section
 An excerpt from the abstract:</description>
    </item>
    
    <item>
      <title>Yi Cheng, &#34;The Unexpected Costs of Expertise: Evidence from Highly Specialized Physicians&#34;</title>
      <link>/posts/jmp-review-yi-cheng/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/jmp-review-yi-cheng/</guid>
      <description>For my first post of the series, “JMP by Women in Economics,” I am reviewing Yi Cheng’s “The Unexpected Costs of Expertise: Evidence from Highly Specialized Physicians”(November 4, 2019). The abstract begins,
 High U.S. spending on health care is commonly attributed to its intensity of specialized, high-tech medical care. A growing body of research focuses on physicians whose medical decisions shape treatment intensity, costs, and patient outcomes. Often overlooked in this research is the assignment of physician skills to patient conditions, which may strongly affect health outcomes and productivity.</description>
    </item>
    
    <item>
      <title>Collecting and parsing tweets, Part III</title>
      <link>/posts/collecting-and-parsing-tweets-part3/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/collecting-and-parsing-tweets-part3/</guid>
      <description>1 Get API key 2 Pass address to Google’s Geocoding API 3 Parse XML 4 if __name__ == &amp;quot;__main__&amp;quot;   Part II of this tutorial series left us with cleaned&amp;lt;fromHour&amp;gt;-&amp;lt;toHour&amp;gt;-&amp;lt;page-count&amp;gt;.json files. Part III will parse the street addresses in those files and geocode them through Google’s Geocoding API.
Here is the directory tree for Part III:
|-- data/ |-- raw/ # from Part I |-- 01_scraped/ # from Part I |-- 02_cleaned/ # from Part II |-- 03_parsed/ # output for Part III will go here |-- counts.</description>
    </item>
    
    <item>
      <title>Collecting and parsing tweets, Part II</title>
      <link>/posts/collecting-and-parsing-tweets-part2/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/collecting-and-parsing-tweets-part2/</guid>
      <description>1 Clean the text 2 Find address in the text 3 if __name__ == &amp;quot;__main__&amp;quot;   Part II will clean the texts and label whether the text contains any street address. Here’s a sketch of the data directory:
|-- data/ |-- raw/ # from Part I |-- 01_scraped/ # from Part I |-- 02_cleaned/ # output for Part II will go here |-- counts.json # from Part I We will use the following packages and set up a logger.</description>
    </item>
    
    <item>
      <title>Collecting and parsing tweets, Part I</title>
      <link>/posts/collecting-and-parsing-tweets-part1/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/collecting-and-parsing-tweets-part1/</guid>
      <description>1 Open a Twitter developer account 2 OAuth2 authentication 3 Count the number of requests to make 4 Retrieve tweets for every hour 4.1 Make search request 4.2 Scrape the response JSON 4.3 Pull the next page token  5 if __name__ == &amp;quot;__main__&amp;quot;   This is the first installment of a multi-part series waking through how I used Twitter API to collect, parse, and extract data for my project, “Locates long polling lines with Twitter data.</description>
    </item>
    
    <item>
      <title>The Central Limit Theorem As I Understand It</title>
      <link>/posts/central-limit-theorem/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/central-limit-theorem/</guid>
      <description>1 The Central Limit Theorem for IID Samples 1.1 The Fetus 1.2 The Baby CLT 1.3 The Adult CLT, v1.0 1.4 The Adult CLT, v2.0  2 The Central Limit Theorem for Non-IID Samples 2.1 Are Agricultural Crop Yields Normally Distributed?  References   According to Salsburg (2001), the Central Limit Theorem (CLT) didn’t have an explicit proof when it was first written down by Abraham de Moivre in the 18th century.</description>
    </item>
    
    <item>
      <title>Taylor Series in Probability</title>
      <link>/posts/taylor-series/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/taylor-series/</guid>
      <description>1 Definition 1.1 Taylor Series of Common Functions  2 Interesting Properties 2.1 Taylor Series Uniqueness 2.2 Taylor’s Theorem  3 Application 3.1 Moment Generating Property 3.2 Mgf of Poisson Distribution 3.3 Moment List of Standard Normal Dist.    I first learned about Taylor series in high school, but I didn’t quite master series expansion in general, let alone Taylor. Even after several math courses in college, my familiarity with it has barely grown since our first encounter back in high school.</description>
    </item>
    
    <item>
      <title>Collecting historical weather data, Part III</title>
      <link>/posts/weather-data-part3/</link>
      <pubDate>Sat, 04 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/weather-data-part3/</guid>
      <description>1 Cleaning the data 2 Visualizing the data References   To recount, Part II interpolated the precipitation data we obtained in Part I in order to get county-level precipitation values. Part III (this post) will clean the data further in preparation for the visualization stage and then create a gif animation of chloreoploth maps plotting precipitation level in inches over the seven days leading up to the 2006 midterm election.</description>
    </item>
    
    <item>
      <title>Geometric and triangle inequalities</title>
      <link>/posts/geometric-and-triangle-inequality/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/geometric-and-triangle-inequality/</guid>
      <description>Geometric inequality Triangle inequality   The last post, “Correlation as standardized covariance”, mentions geometric and triangle inequalities, i.e.
 geometric inequality: \(\left| ab \right| \leq \dfrac{a^2 + b^2}{2}\) for all \(a, b \in \mathbb{R}\) triangle inequality for expectations: \(\left| E [X] \right| \leq E [ \left| X \right|]\) for a discrete or continuous random variable \(X\).  They look deceptively simple and intuitive, but I was surprised by how frequently they can be used in proofs.</description>
    </item>
    
    <item>
      <title>Correlation is just standardized covariance</title>
      <link>/posts/correlation-is-just-standardized-covariance/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/correlation-is-just-standardized-covariance/</guid>
      <description>Sometimes, we re-learn a concept in a new way that opens our eyes and feel like we finally get it. This happened to me with correlation: the correlation of two random variables is just standardized covariance!
I learned the material in this article from taking Professor Daniel Weiner’s course, Mathematics of Statistics at BU. All the credit of this post goes to him while all mistakes are mine. 💁  In this post, I want to show the math behind that statement and demonstrate how defining correlation this way makes it easier to understand the Cauchy-Schwartz Inequality.</description>
    </item>
    
    <item>
      <title>Lessons from Kaggle CareerCon 2019</title>
      <link>/posts/kaggle-careercon2019/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/kaggle-careercon2019/</guid>
      <description>Lesson: A PhD is neither necessary nor worthless. Lesson: Do your own projects and share them. Lesson: Product analytics sounds a lot like social science research. Conclusion: Am I ready for a data science job? References   Kaggle hosted a live-stream career conference from April 16th to 18th. I was not able to join the Slack channel, but otherwise I was able to view the live stream on Kaggle’s YouTube channel.</description>
    </item>
    
    <item>
      <title>Collecting historical weather data, Part II</title>
      <link>/posts/weather-data-part2/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/weather-data-part2/</guid>
      <description>1 Reproject shapefile 2 Perform Kriging interpolation 3 Reproject raster layer 4 Obtain average total rainfall for each county References   prcp_data we created in Part I is not useful in and of itself because it only shows precipitation values recorded by weather stations. Ultimately, I want to be able to say that county \(i\) for \(i = 1, \ldots, n\) on day \(t\) for \(t = 1, \ldots, T\) had \(x_{it}\) level of precipitation.</description>
    </item>
    
    <item>
      <title>Collecting historical weather data, Part I</title>
      <link>/posts/weather-data-part1/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/weather-data-part1/</guid>
      <description>1 Obtain NOAA API key token 2 Obtain weather data with rnoaa::ncdc() 2.1 Code breakdown  3 Obtain weather station data with rnoaa::ncdc_stations() 4 Join dataframes 5 Create spatial point dataframes 6 (Optional) Plot the data   As part of a coauthored project investigating whether rain deters voters from going to the polls in US elections, I had to collect past weather data. This series walks you through how to gather data on the daily total precipitation level from November 1st to November 7th, 2006, where the last day is the 2006 midterm election.</description>
    </item>
    
    <item>
      <title>Introducing a replication project of Warren (2019)</title>
      <link>/posts/introduce-replicate-warren/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/introduce-replicate-warren/</guid>
      <description>I have a project called replicate_warren (a private Github repository), where I am trying to replicate a sociology study, Warren (2019). To put it succinctly, Warren (2019) collected data from résumés of sociology PhD graduates and measured how over-achieving recent PhD graduates had to be to land a junior faculty jobs at top sociology departments in the United States. I want to replicate the study in the political science field.</description>
    </item>
    
  </channel>
</rss>